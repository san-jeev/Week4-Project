{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weeek4 - Homework : Chest X-Ray Image Classification (Normal or Pneumonia) using Transfer Learning \n",
    "#1- Download Chest X-Ray Image Data From Kaggle\n",
    "#2- Plot Normal and Pneumonia Chest X-Ray Images\n",
    "#3- Chest X-Ray Image Preprocessing/ Augmentation/ Transformation for Model Training, Validation and Testing Dataset\n",
    "#4- Create InceptionV3 Base CNN Model\n",
    "#5- Create a Sequential Model for traing & prediction. Add base model, pooling layer & fully connected Dense layers\n",
    "#6- Compile the Sequential Model and Display Model Summary\n",
    "#7- Fit and Train the Sequential Model and Display Results\n",
    "#8- Evaluate the Sequential Model Performance and Show Results\n",
    "#9- Test the pre-trained Sequential Model and Show Results\n",
    "# Work below is based on Anjana Tiha github project at https://github.com/anjanatiha/Pneumonia-Detection-from-Chest-X-Ray-Images-with-Deep-Learning/blob/master/code/Detection%20of%20Pneumonia%20from%20Chest%20X-Ray%20Images%201.0.0.3.ipynb\n",
    "import os #for OS dependent functionalities\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "import numpy as np # data presprocessing\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt # visualize the data\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "import math, json\n",
    "import datetime\n",
    "import random\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image  #Python Imaging Library\n",
    "from pathlib import Path\n",
    "from glob import glob # find pathnames for images matching specified pattern \n",
    "import keras\n",
    "# Inception-v3 is convolution neural network trained on million+ images from ImageNet db. \n",
    "# The network is 48 layers deep and can classify images into 1000 object categories\n",
    "# The Inception-v3 model expects color images to have the square shape 299×299.\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator #to perform image augmentation on the fly & easy way\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD , RMSprop\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import torch # to save model etc on google colab drive \n",
    "from google.colab import drive # to save model etc on google colab drive\n",
    "\n",
    "#!pip install tensorflow --upgrade\n",
    "#!pip install keras --upgrade\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "print(\"Keras version \" + keras.__version__)\n",
    "\n",
    "print(\"Numpy version \" + np.__version__)\n",
    "\n",
    "\n",
    "#################### Download Chest X-Ray Image Data From Kaggle #############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mDownload Chest X-Ray Data From Kaggle\\033[0m' + \"\\n\")\n",
    "# Setup the Kaggle environemt for image download\n",
    "#os.environ['KAGGLE_USERNAME'] = 'XXXX'\n",
    "#os.environ['KAGGLE_KEY'] = 'XXXXXXX'\n",
    "# Dowmload the Kaggle Chest X-Ray dataset \n",
    "#!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "# unzip the chest x-ray images \n",
    "#!unzip chest-xray-pneumonia.zip\n",
    "#!unzip chest_xray.zip\n",
    "\n",
    "#################### Plot Normal and Pneumonia Chest X-Ray Images #############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mPlot Normal and Pneumonia Chest X-Ray Images\\033[0m' + \"\\n\")\n",
    "\n",
    "# Define and configure file directories for train, validate and test image dataset\n",
    "training_dir = './chest_xray/train'\n",
    "validate_dir = './chest_xray/val'\n",
    "test_dir = './chest_xray/test'\n",
    "\n",
    "# Plot an image of Normal Chest Xray\n",
    "plt.figure(1, figsize = (12 , 6))\n",
    "plt.subplot(1 , 2 , 1)\n",
    "print('Number of Normal Images: ' + str(len(glob(training_dir+\"/NORMAL/*.jpeg\"))))\n",
    "img = np.asarray(plt.imread(glob(training_dir+\"/NORMAL/*.jpeg\")[0]))\n",
    "plt.title('Normal Chest X-Ray')\n",
    "plt.imshow(img)\n",
    "\n",
    "# Plot an image of Pneumonia Chest Xray\n",
    "plt.subplot(1 , 2 , 2)\n",
    "img = np.asarray(plt.imread(glob(training_dir+\"/PNEUMONIA/*.jpeg\")[0]))\n",
    "print('Number of Pneumonia Images: '  + str(len(glob(training_dir+\"/PNEUMONIA/*.jpeg\"))))\n",
    "print(\"\")\n",
    "plt.title('Pneumonia Chest X-Ray')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "######### Chest X-Ray Image Preprocessing/ Augmentation/ Transformation for Model Training, Validation and Testing Dataset ##########\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mImage Preprocessing/ Augmentation/ Transformation for Training, Validation and Testing Dataset\\033[0m' + \"\\n\")\n",
    "\n",
    "# Define Constants used  \n",
    "# Rescale the pixel values (between 0 and 255) to [0, 1] interval \n",
    "# Neural networks perform better with normalize data.  \n",
    "# rescale normalizes the image pixel values to have zero mean & standard deviation of 1. \n",
    "rescale = 1./255 # Scale the image between 0 and 1\n",
    "target_size = (150, 150)  # by keras doc, conv2d input shape should be (height, width) == (row, colum) sequence\n",
    "batch_size=32\n",
    "img_height=150\n",
    "img_width=150   \n",
    "\n",
    "# Use ImageDataGenerator() so Python generators that automatically turn image files into preprocessed tensors that can be fed directly into models during trainng.\n",
    "#1. Decode the JPEG content to RGB grids of pixels.\n",
    "#2. Convert these into floating-point tensors.\n",
    "#3. Rescale the pixel values (between 0 and 255) to the [0, 1] interval ( neural networks perform better with normalize data).\n",
    "#4. Helps us easily augment images.             \n",
    "\n",
    "# Create Training Image Data Generator and augument the training images to augment our data-set and improve generalization.\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "print('Training Data Generation')\n",
    "# this is the augmentation configuration we will use for training\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=32\n",
    ")\n",
    "print('Training classes are' + str(training_generator.class_indices) + '\\n')\n",
    "\n",
    "\n",
    "# Create Vaildation Image Data Generator\n",
    "# No image data augumentation for validation image data generation, only rescale\n",
    "validation_datagen = ImageDataGenerator(rescale=rescale)\n",
    "print('\\n' + 'Validation Data Generation')\n",
    "# this is the augmentation configuration we will use for validation\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validate_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=32\n",
    ")\n",
    "print('Validation classes are' + str(validation_generator.class_indices) + '\\n')\n",
    "\n",
    "# Create Testing Image Data Generator\n",
    "test_datagen = ImageDataGenerator(rescale=rescale)\n",
    "print('\\n' + 'Test Data Generation')\n",
    "# this is the augmentation configuration we will use for testing\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode='binary',\n",
    "    batch_size=1\n",
    ")\n",
    "print('Test classes are' + str(test_generator.class_indices))\n",
    "\n",
    "######################## Create InceptionV3 Base CNN Model ####################################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mCreating Pre-Trained InceptionV3 Base Model For Transfer Learning\\033[0m' + \"\\n\")\n",
    "\n",
    "# A Convolutional Neural Network (CNN) architecture has three main parts:\n",
    "# A convolutional layer that extracts features from a source image. Convolution helps with blurring, sharpening, edge detection, noise reduction, or other operations that can help the machine to learn specific characteristics of an image.\n",
    "# A pooling layer that reduces the image dimensionality without losing important features or patterns.\n",
    "# A fully connected layer also known as the dense layer, in which the results of the convolutional layers are fed through one or more neural layers to generate a prediction.\n",
    "\n",
    "# Create the base pre-trained InceptionV3 CNN model for image processing\n",
    "# “include_top” argument set to False so fully-connected output layers of the model \n",
    "# used to make predictions is not loaded, allowing a new output layer to be added and trained.\n",
    "# A model without a top will output activations from the last convolutional or pooling layer directly.\n",
    "# Your input should be input_shape=(img_rows, img_cols, 3 channels RGB)  or (batchSize, height, width, feature/channels)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "######################## Create a Sequential Model for traing & prediction. Add base model, pooling layer & fully connected Dense layers ################\n",
    "# Initializing the network using the Sequential Class\n",
    "# The Sequential model (a linear stack of layers) is a prediction model which is trained with a set of training sequences. \n",
    "# Once trained, the sequential model is used to perform sequence predictions.\n",
    "# Sequential class which is a linear stack of Layers where after creating you can define all of the layers in the constructor\n",
    "model = Sequential()\n",
    "# Add the convolution layer by adding the pre-trained InceptionV3 base model output\n",
    "model.add(base_model)\n",
    "# Add a pooling layer by adding global spatial average pooling layer\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "# Add a fully-connected layer;\n",
    "model.add(Dense(1024, activation='relu'))  # rectified linear unit \n",
    "# Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "model.add(Dropout(0.5))\n",
    "# Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "# Model output arrays will be of shape (*, 8)\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "# Add logistic layer \n",
    "# Using 1 class for binary classification with activation sigmoid\n",
    "# Model output arrays will be of shape (*, 1)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "######################## Compile the Model and Display Model Summary #####################\n",
    "\n",
    "print('Compiling The Model' + \"\\n\")\n",
    "\n",
    "model.compile(loss= 'binary_crossentropy',\n",
    "              optimizer='rmsprop',          # root mean square propagation\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Displaying The Model Summary Information below' + \"\\n\")\n",
    "model.summary() \n",
    "print(\"\")\n",
    "\n",
    "######################## Fit and Train the Sequential Model and Display Results ####################################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mStarting to Fit and Train The Model\\033[0m' + \"\\n\")\n",
    "\n",
    "# Train the model on data generated batch-by-batch by a Python generator \n",
    "# Train the model for defined epochs for steps_per_epoch times in each epoch \n",
    "# An epoch usually means one iteration over all of the training data. \n",
    "# For instance for 20,000 images and a batch size of 100, the epoch should contain 20,000 / 100 = 200 steps. \n",
    "\n",
    "steps_per_epoch=len(training_generator)\n",
    "print('steps_per_epoch is ' + str(steps_per_epoch) + '\\n')\n",
    "validation_steps=len(validation_generator)\n",
    "print('validation_steps is ' + str(validation_steps) + '\\n')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,  \n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    ")\n",
    "\n",
    "# Save the Weights and the Model\n",
    "print(\"\")\n",
    "drive.mount('/content/gdrive')   # if drive is dismounted then will need to forget previous authentication key and reauthenticate\n",
    "model_save_name = 'ChestXRayClassifier.pt'\n",
    "model_path_filename = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
    "print('\\n' + 'Saving the trained model at %s ' % path)\n",
    "torch.save(model, model_path_filename)   #torch.save(model.state_dict(), path) gives error\n",
    "\n",
    "# Plot the Model and its layers\n",
    "path = F\"/content/gdrive/My Drive\" \n",
    "plot_model(model, to_file='chest-xray-classification-model.png')\n",
    "model_img = Image.open(\"chest-xray-classification-model.png\")\n",
    "plt.figure(1, figsize = (16 , 16))\n",
    "plt.title('Trained Model')\n",
    "plt.imshow(model_img)\n",
    "\n",
    "print('\\n' \"Completed Model Fitting and Training\" '\\n')\n",
    "\n",
    "######################## Evaluate Model Performance ###############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mPerform and Plot Model Performance Evaluation\\033[0m' + \"\\n\")\n",
    "\n",
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['acc']\n",
    "y2 = history.history['val_acc']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()\n",
    "\n",
    "######################## Test the pre-trained Sequential Model and Show Results ###############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mTesting The Trained Model\\033[0m' + \"\\n\")\n",
    "\n",
    "test_steps=len(test_generator)\n",
    "results = model.evaluate_generator(generator=test_generator, steps=test_steps, verbose=1)\n",
    "print('\\n' + 'Trained Model Testing Results: Loss and Accuracy: ' + str(results))\n",
    "\n",
    "history = model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=5,  \n",
    "    verbose=1,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    ")\n",
    "\n",
    "# Save the Weights and the Model\n",
    "print(\"\")\n",
    "drive.mount('/content/gdrive')   # if drive is dismounted then will need to forget previous authentication key and reauthenticate\n",
    "model_save_name = 'ChestXRayClassifier.pt'\n",
    "model_path_filename = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
    "print('\\n' + 'Saving the trained model at %s ' % path)\n",
    "torch.save(model, model_path_filename)   #torch.save(model.state_dict(), path) gives error\n",
    "\n",
    "# Plot the Model and its layers\n",
    "path = F\"/content/gdrive/My Drive\" \n",
    "plot_model(model, to_file='chest-xray-classification-model.png')\n",
    "model_img = Image.open(\"chest-xray-classification-model.png\")\n",
    "plt.figure(1, figsize = (16 , 16))\n",
    "plt.title('Trained Model')\n",
    "plt.imshow(model_img)\n",
    "\n",
    "print('\\n' \"Completed Model Fitting and Training\" '\\n')\n",
    "\n",
    "######################## Evaluate Model Performance ###############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mPerform and Plot Model Performance Evaluation\\033[0m' + \"\\n\")\n",
    "\n",
    "xlabel = 'Epoch'\n",
    "legends = ['Training', 'Validation']\n",
    "\n",
    "ylim_pad = [0.01, 0.1]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training & validation Accuracy values\n",
    "\n",
    "y1 = history.history['acc']\n",
    "y2 = history.history['val_acc']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Accuracy', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "# Plot training & validation loss values\n",
    "    \n",
    "y1 = history.history['loss']\n",
    "y2 = history.history['val_loss']\n",
    "\n",
    "min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(y1)\n",
    "plt.plot(y2)\n",
    "\n",
    "plt.title('Model Loss', fontsize=17)\n",
    "plt.xlabel(xlabel, fontsize=15)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.ylim(min_y, max_y)\n",
    "plt.legend(legends, loc='upper left')\n",
    "plt.grid()\n",
    "                         \n",
    "plt.show()\n",
    "\n",
    "######################## Test the trained Model ###############################\n",
    "\n",
    "print(\"\\n\" + '\\033[1m \\033[4mTesting The Trained Model\\033[0m' + \"\\n\")\n",
    "\n",
    "test_steps=len(test_generator)\n",
    "results = model.evaluate_generator(generator=test_generator, steps=test_steps, verbose=1)\n",
    "print('\\n' + 'Trained Model Testing Results: Loss and Accuracy: ' + str(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
